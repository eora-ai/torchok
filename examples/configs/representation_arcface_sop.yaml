task:
  name: ClassificationTask
  compute_loss_on_valid: False
  params:
    backbone_name: semnasnet_100
    backbone_params:
      pretrained: true
      in_channels: 3
    pooling_name: PoolingLinear
    pooling_params:
      out_channels: 512
    head_name: ArcFaceHead
    head_params:
      num_classes: &num_classes 11318
    inputs:
      - shape: [3, &height 256, &width 256]
        dtype: &input_dtype float32

joint_loss:
  losses:
    - name: CrossEntropyLoss
      mapping:
          input: prediction
          target: target

optimization:
  - optimizer:
      name: SGD
      params:
        lr: &initial_lr 0.001
        momentum: 0.9
        nesterov: true
        weight_decay: 0.00005

data:
  TRAIN:
    - dataloader:
        batch_size: 64
        num_workers: 4
        drop_last: true
        shuffle: true
      dataset:
        name: SOP
        params:
          input_dtype: *input_dtype
          train: true
          download: true
          data_folder: &data_folder ${oc.env:HOME}/.cache/torchok/data/sop
        transform:
          - &resize
            name: Resize
            params:
              height: *height
              width: *width
          - &normalize
            name: Normalize
            params:
              mean: [ 0.485, 0.456, 0.406 ]
              std: [ 0.229, 0.224, 0.225 ]
          - &totensor
            name: ToTensorV2
        augment:
          - name: HorizontalFlip
          - name: VerticalFlip
          - name: Compose
            params:
              p: 0.5
              transforms:
                - name: PadIfNeeded
                  params:
                    min_height: *height
                    min_width: *width
                - name: CenterCrop
                  params:
                    height: *height
                    width: *width
          - name: OneOf
            params:
              p: 1.0
              transforms:
                - name: ElasticTransform
                  params:
                    border_mode: 1
                - name: GridDistortion
                - name: GaussNoise
                - name: ColorJitter
                  params:
                    brightness: 0.4
                    contrast: 0.4
                    saturation: 0.4
                    hue: 0.1
          - name: OneOf
            params:
              p: 1.0
              transforms:
                - name: ElasticTransform
                  params:
                    border_mode: 1
                - name: GridDistortion
                - name: GaussNoise
                - name: ColorJitter
                  params:
                    brightness: 0.4
                    contrast: 0.4
                    saturation: 0.4
                    hue: 0.1
  VALID:
    - dataloader:
        batch_size: 64
        num_workers: 16
        drop_last: false
        shuffle: false
      dataset:
        name: SOP
        params:
          input_dtype: *input_dtype
          train: false
          download: true
          data_folder: *data_folder
        transform:
          - *resize
          - *normalize
          - *totensor

trainer:
  accelerator: 'gpu'
  max_epochs: 30
  precision: 32
  num_sanity_val_steps: 0

logger:
  log_dir: '${oc.env:HOME}/.cache/torchok/logs/'
  experiment_name: sop
  timestamp: '${now:%Y-%m-%d}/${now:%H-%M-%S}'
  name: TensorBoardLogger

hydra:
  run:
    dir: &logs_dir '${logger.log_dir}/${logger.experiment_name}/${logger.timestamp}'

callbacks:
  - name: FreezeUnfreeze
    params:
      freeze_modules:
#        The whole backbone will be frozen during the first 2 epochs.
        - module_name: backbone
          epoch: 2
#        Stem and the first layer of the backbone will be frozen forever during the training.
        - module_name: backbone
          stage: 1
#        Only the modules of type `_BatchNorm` that attached to the backbone will be frozen
#         with the specific policy: requires_grad of all batch norms will be set to false but
#         these modules will track
        - module_name: backbone
          module_class: _BatchNorm  # or `BatchNorm2d` for certain type of batch norm
          bn_requires_grad: false
          bn_track_running_stats: false
#        All dropouts in the network will be disabled forever during the training
        - module_name: ""
          module_class: Dropout
  - name: ModelCheckpointWithOnnx
    params:
      dirpath: *logs_dir
      monitor: valid/HitAtKMeter
      save_top_k: 2
      save_last: true
      mode: min
      save_weights_only: False
      export_to_onnx: true
      remove_head: true
  - name: FinalizeLogger
  - name: TQDMProgressBar
    params:
      refresh_rate: 5

metrics:
  - name: Accuracy
    mapping: 
      preds: prediction
      target: target
    phases: [TRAIN]

  - name: HitAtKMeter
    params:
      k: 1
      dataset_type: classification
      normalize_vectors: True
      search_batch_size: 256
    mapping:
      vectors: embeddings
      targets: target
    phases: [VALID]
