task:
  name: SimMIMTask
  params:
    backbone_name: swinv2_custom
    backbone_params:
      pretrained: false
      in_channels: 3
      img_size: 192
      embed_dim: 128
      depths: [ 2, 2, 18, 2 ]
      num_heads: [ 4, 8, 16, 32 ]
      window_size: 6
    pooling_name: Pooling
    mask_patch_size: 32
    mask_ratio: 0.6
    encoder_stride: 32
    inputs:
      - shape: [3, &height 192, &width 192]
        dtype: &input_dtype bfloat16

joint_loss:
  losses:
    - name: Identity
      mapping:
          input: loss

optimization:
  - optimizer: 
      name: Adam
      params:
        lr: &base_lr 0.0001
        weight_decay: 0.05
    scheduler:
      name: OneCycleLR
      params:
        max_lr: *base_lr
        epochs: 100
        steps_per_epoch: 930
      pl_params:
        interval: step

data:
  TRAIN:
    - dataloader:
        batch_size: 32
        num_workers: 8
        drop_last: true
        shuffle: true
      dataset:
        name: CIFAR10
        params:
          input_dtype: *input_dtype
          train: true
          download: true
          data_folder: &data_folder ${oc.env:HOME}/cifar10
        transform:
          - &resize
            name: Resize
            params:
              height: *height
              width: *width
          - &normalize
            name: Normalize
            params:
              mean: [ 0.485, 0.456, 0.406 ]
              std: [ 0.229, 0.224, 0.225 ]
          - &totensor
            name: ToTensorV2
  VALID:
    - dataloader:
        batch_size: 32
        num_workers: 8
        drop_last: false
        shuffle: false
      dataset:
        name: CIFAR10
        params:
          input_dtype: *input_dtype
          train: false
          download: true
          data_folder: *data_folder
        transform:
          - *resize
          - *normalize
          - *totensor

trainer:
  accelerator: 'gpu'
  max_epochs: 100
  limit_val_batches: 10
  precision: bf16
  num_sanity_val_steps: 0
  accumulate_grad_batches: 4

hydra:
  run:
    dir: &logs_dir '${logger.log_dir}/${logger.experiment_name}/${logger.timestamp}'

logger:
  log_dir: '${oc.env:HOME}/logs/'
  experiment_name: simmim_cifar10
  timestamp: '${now:%Y-%m-%d}/${now:%H-%M-%S}'
  name: TensorBoardLogger

callbacks:
  - name: ModelCheckpoint
    params:
      dirpath: *logs_dir
      monitor: train/loss
      save_top_k: 1
      save_last: true
      mode: max
      save_weights_only: False
  - name: FinalizeLogger
  - name: TQDMProgressBar
    params:
      refresh_rate: 5

