{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from omegaconf import OmegaConf, DictConfig, ListConfig\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from torchok.constructor.config_structure import DatasetParams\n",
    "from torchok.constructor.constructor import Constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.9/site-packages/albumentations/core/composition.py:53: UserWarning: transforms is single transform, but a sequence is expected! Transform will be wrapped into list.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torchok.data.datasets.detection.detection.DetectionDataset at 0x7fcb7b4b28b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_params = {\n",
    "    'data_folder': '/workdir/rbayazitov/detection/val2017/',\n",
    "    'csv_path': '/workdir/rbayazitov/detection/valid.csv'\n",
    "}\n",
    "\n",
    "transform = ListConfig([\n",
    "    DictConfig({\n",
    "        'name': 'Resize',\n",
    "        'params': {\n",
    "            'width': 224,\n",
    "            'height': 224\n",
    "        }\n",
    "    }),\n",
    "    DictConfig({\n",
    "        'name': 'ToTensorV2',\n",
    "        'params': {\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    ]\n",
    ")\n",
    "\n",
    "daset_params = {\n",
    "    'name': 'DetectionDataset',\n",
    "    'params': data_params,\n",
    "    'transform': transform\n",
    "}\n",
    "\n",
    "dataset_params = DatasetParams(name='DetectionDataset', params=data_params, transform=[transform])\n",
    "\n",
    "dataset = Constructor._create_dataset(DictConfig(daset_params))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44, 67, 1, 49, 51, 51, 79, 1, 47, 47, 51, 51, 56, 50, 56, 56, 79, 57, 81]\n",
      "tensor([44, 67,  1, 49, 51, 51, 79,  1, 47, 47, 51, 51, 56, 50, 56, 56, 79, 57,\n",
      "        81])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[120., 103.,  77.,  ...,  13.,  13.,  10.],\n",
       "          [123.,  92.,  82.,  ...,  10.,  15.,  42.],\n",
       "          [120., 100.,  73.,  ...,  14.,  14.,  23.],\n",
       "          ...,\n",
       "          [136., 141., 143.,  ...,  49.,  53.,  51.],\n",
       "          [141., 138., 141.,  ...,  49.,  51.,  49.],\n",
       "          [143., 141., 142.,  ...,  51.,  52.,  50.]],\n",
       " \n",
       "         [[130., 116.,  86.,  ...,   6.,  14.,  10.],\n",
       "          [135., 104.,  86.,  ...,  13.,  14.,  41.],\n",
       "          [136., 102.,  78.,  ...,  16.,  12.,  26.],\n",
       "          ...,\n",
       "          [107., 106., 110.,  ...,  37.,  38.,  37.],\n",
       "          [106., 107., 107.,  ...,  37.,  36.,  33.],\n",
       "          [109., 108., 109.,  ...,  37.,  36.,  32.]],\n",
       " \n",
       "         [[ 68.,  63.,  68.,  ...,  11.,  12.,  11.],\n",
       "          [ 72.,  53.,  84.,  ...,  10.,  13.,  39.],\n",
       "          [ 69.,  56.,  57.,  ...,  14.,  13.,  23.],\n",
       "          ...,\n",
       "          [ 77.,  78.,  78.,  ...,  23.,  27.,  26.],\n",
       "          [ 78.,  76.,  77.,  ...,  27.,  26.,  25.],\n",
       "          [ 75.,  74.,  76.,  ...,  27.,  27.,  23.]]]),\n",
       " 'index': 0,\n",
       " 'label': tensor([44, 67,  1, 49, 51, 51, 79,  1, 47, 47, 51, 51, 56, 50, 56, 56, 79, 57,\n",
       "         81]),\n",
       " 'bboxes': tensor([[ 76.1670, 126.1849,  13.6465,  30.2951],\n",
       "         [  0.3500, 126.0275, 121.3205,  97.9725],\n",
       "         [136.0310,  36.6793,  38.2935, 145.6367],\n",
       "         [ 47.4495, 130.8485,   7.8120,  15.1030],\n",
       "         [ 10.9480, 180.4590,  23.8420,  21.4190],\n",
       "         [ 20.8705, 150.7462,  26.6245,  21.6656],\n",
       "         [  0.4760,  86.2059,  67.3960,  51.6039],\n",
       "         [  0.0000, 137.8675,  21.7560,  19.2892],\n",
       "         [ 41.7900, 142.9561,   8.6870,  17.9672],\n",
       "         [ 49.5145, 140.5430,  11.2665,  18.8118],\n",
       "         [ 54.5895,  88.6295,   9.1105,   8.9862],\n",
       "         [ 55.0200,  59.8820,   6.2510,   8.2990],\n",
       "         [ 34.5625, 159.8846,   3.7730,   2.9220],\n",
       "         [ 58.1105, 134.4839,   3.0870,   9.7469],\n",
       "         [ 30.2435, 154.2138,   8.3860,   5.8649],\n",
       "         [ 24.5490, 155.3626,   3.2480,   2.4026],\n",
       "         [  0.0000, 110.6361,  66.9760,  51.9239],\n",
       "         [ 33.8415, 155.8505,   2.7440,   2.5495],\n",
       "         [174.0375, 106.7016,  42.7035,  15.0085]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_COLOR = (255, 0, 0) # Red\n",
    "TEXT_COLOR = (255, 255, 255) # White\n",
    "\n",
    "\n",
    "def visualize_bbox(img, bbox, class_name, color=BOX_COLOR, thickness=2):\n",
    "    \"\"\"Visualizes a single bounding box on the image\"\"\"\n",
    "    x_min, y_min, w, h = bbox\n",
    "    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
    "   \n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "    \n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
    "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        text=class_name,\n",
    "        org=(x_min, y_min - int(0.3 * text_height)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=0.35, \n",
    "        color=TEXT_COLOR, \n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    return img\n",
    "\n",
    "\n",
    "def visualize(image, bboxes, category_ids, category_id_to_name):\n",
    "    img = image.copy()\n",
    "    for bbox, category_id in zip(bboxes, category_ids):\n",
    "        class_name = str(category_id_to_name[category_id])\n",
    "        img = visualize_bbox(img, bbox, class_name)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torchok')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d98e06cf72c4d3f13daa3b7355ff9823c938a29cb0c8751ac8d58eb5a0740c19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
