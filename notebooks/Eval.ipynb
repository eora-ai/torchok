{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.pyplot import imshow\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.nn import Module\n",
    "from torchsummary import summary\n",
    "\n",
    "from collections import namedtuple, defaultdict\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = (10, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constructor.config_structure import TrainConfigParams\n",
    "from src.registry import TASKS\n",
    "from src.constructor.data import create_dataset\n",
    "from src.constructor.trainer import download_s3_artifact\n",
    "from train import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hparams(config_path):\n",
    "    hparams = load_config(config_path)\n",
    "    hparams = TrainConfigParams(**hparams)\n",
    "    \n",
    "    return hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '../configs/detection.yml'\n",
    "config = load_hparams(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent XBM from loading\n",
    "config.task.params['xbm_params'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetectionTask(\n",
       "  (criterion): JointLoss(\n",
       "    (losses): ModuleList(\n",
       "      (0): DiceLoss()\n",
       "      (1): LovaszLoss()\n",
       "      (2): BCEWithLogitsLoss()\n",
       "    )\n",
       "  )\n",
       "  (backbone): CSPDarknet(\n",
       "    (stem): Focus(\n",
       "      (conv): ConvModule(\n",
       "        (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (activate): Swish()\n",
       "      )\n",
       "    )\n",
       "    (stage1): Sequential(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (activate): Swish()\n",
       "      )\n",
       "      (1): CSPLayer(\n",
       "        (main_conv): ConvModule(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (short_conv): ConvModule(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (final_conv): ConvModule(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): DarknetBottleneck(\n",
       "            (conv1): ConvModule(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "            (conv2): ConvModule(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage2): Sequential(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (activate): Swish()\n",
       "      )\n",
       "      (1): CSPLayer(\n",
       "        (main_conv): ConvModule(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (short_conv): ConvModule(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (final_conv): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): DarknetBottleneck(\n",
       "            (conv1): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "            (conv2): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "          )\n",
       "          (1): DarknetBottleneck(\n",
       "            (conv1): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "            (conv2): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "          )\n",
       "          (2): DarknetBottleneck(\n",
       "            (conv1): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "            (conv2): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (activate): Swish()\n",
       "      )\n",
       "      (1): CSPLayer(\n",
       "        (main_conv): ConvModule(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (short_conv): ConvModule(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (final_conv): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): DarknetBottleneck(\n",
       "            (conv1): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "            (conv2): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "          )\n",
       "          (1): DarknetBottleneck(\n",
       "            (conv1): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "            (conv2): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "          )\n",
       "          (2): DarknetBottleneck(\n",
       "            (conv1): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "            (conv2): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage4): Sequential(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (activate): Swish()\n",
       "      )\n",
       "      (1): SPPBottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (poolings): ModuleList(\n",
       "          (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "          (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "          (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "      )\n",
       "      (2): CSPLayer(\n",
       "        (main_conv): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (short_conv): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (final_conv): ConvModule(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): DarknetBottleneck(\n",
       "            (conv1): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "            (conv2): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d', 'a': 2.23606797749979, 'distribution': 'uniform', 'mode': 'fan_in', 'nonlinearity': 'leaky_relu'}\n",
       "  (neck): YOLOXPAFPN(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (reduce_layers): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (activate): Swish()\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (activate): Swish()\n",
       "      )\n",
       "    )\n",
       "    (top_down_blocks): ModuleList(\n",
       "      (0): CSPLayer(\n",
       "        (main_conv): ConvModule(\n",
       "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (short_conv): ConvModule(\n",
       "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (final_conv): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): DarknetBottleneck(\n",
       "            (conv1): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "            (conv2): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): CSPLayer(\n",
       "        (main_conv): ConvModule(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (short_conv): ConvModule(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (final_conv): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): DarknetBottleneck(\n",
       "            (conv1): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "            (conv2): ConvModule(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (downsamples): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (activate): Swish()\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (activate): Swish()\n",
       "      )\n",
       "    )\n",
       "    (bottom_up_blocks): ModuleList(\n",
       "      (0): CSPLayer(\n",
       "        (main_conv): ConvModule(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (short_conv): ConvModule(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (final_conv): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): DarknetBottleneck(\n",
       "            (conv1): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "            (conv2): ConvModule(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): CSPLayer(\n",
       "        (main_conv): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (short_conv): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (final_conv): ConvModule(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): DarknetBottleneck(\n",
       "            (conv1): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "            (conv2): ConvModule(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (activate): Swish()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (activate): Swish()\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (activate): Swish()\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (activate): Swish()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Kaiming', 'layer': 'Conv2d', 'a': 2.23606797749979, 'distribution': 'uniform', 'mode': 'fan_in', 'nonlinearity': 'leaky_relu'}\n",
       "  (head): YOLOXHead(\n",
       "    (multi_level_cls_convs): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (multi_level_reg_convs): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (activate): Swish()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (multi_level_conv_cls): ModuleList(\n",
       "      (0): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (multi_level_conv_reg): ModuleList(\n",
       "      (0): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (multi_level_conv_obj): ModuleList(\n",
       "      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint = torch.load(download_s3_artifact('s3://ml-fips/mlruns/eedfa4c178bd44f8bc6c44cdcc0f4814/artifacts/last.ckpt', '/tmp'), map_location=device)\n",
    "model = TASKS.get(config.task.name)(config)\n",
    "# model = model.to(device)\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "# model.eval();\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "batch = torch.zeros((4, 3, 640, 640))\n",
    "\n",
    "answer = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2, 80, 80]),\n",
       " torch.Size([4, 2, 40, 40]),\n",
       " torch.Size([4, 2, 20, 20]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[0][0].shape, answer[0][1].shape, answer[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 4, 80, 80]),\n",
       " torch.Size([4, 4, 40, 40]),\n",
       " torch.Size([4, 4, 20, 20]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[1][0].shape, answer[1][1].shape, answer[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1, 80, 80]),\n",
       " torch.Size([4, 1, 40, 40]),\n",
       " torch.Size([4, 1, 20, 20]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[2][0].shape, answer[2][1].shape, answer[2][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.modules.utils import _pair\n",
    "\n",
    "\n",
    "class PointGenerator:\n",
    "\n",
    "    def _meshgrid(self, x, y, row_major=True):\n",
    "        xx = x.repeat(len(y))\n",
    "        yy = y.view(-1, 1).repeat(1, len(x)).view(-1)\n",
    "        if row_major:\n",
    "            return xx, yy\n",
    "        else:\n",
    "            return yy, xx\n",
    "\n",
    "    def grid_points(self, featmap_size, stride=16, device='cuda'):\n",
    "        feat_h, feat_w = featmap_size\n",
    "        shift_x = torch.arange(0., feat_w, device=device) * stride\n",
    "        shift_y = torch.arange(0., feat_h, device=device) * stride\n",
    "        shift_xx, shift_yy = self._meshgrid(shift_x, shift_y)\n",
    "        stride = shift_x.new_full((shift_xx.shape[0], ), stride)\n",
    "        shifts = torch.stack([shift_xx, shift_yy, stride], dim=-1)\n",
    "        all_points = shifts.to(device)\n",
    "        return all_points\n",
    "\n",
    "    def valid_flags(self, featmap_size, valid_size, device='cuda'):\n",
    "        feat_h, feat_w = featmap_size\n",
    "        valid_h, valid_w = valid_size\n",
    "        assert valid_h <= feat_h and valid_w <= feat_w\n",
    "        valid_x = torch.zeros(feat_w, dtype=torch.bool, device=device)\n",
    "        valid_y = torch.zeros(feat_h, dtype=torch.bool, device=device)\n",
    "        valid_x[:valid_w] = 1\n",
    "        valid_y[:valid_h] = 1\n",
    "        valid_xx, valid_yy = self._meshgrid(valid_x, valid_y)\n",
    "        valid = valid_xx & valid_yy\n",
    "        return valid\n",
    "\n",
    "\n",
    "class MlvlPointGenerator:\n",
    "    \"\"\"Standard points generator for multi-level (Mlvl) feature maps in 2D\n",
    "    points-based detectors.\n",
    "\n",
    "    Args:\n",
    "        strides (list[int] | list[tuple[int, int]]): Strides of anchors\n",
    "            in multiple feature levels in order (w, h).\n",
    "        offset (float): The offset of points, the value is normalized with\n",
    "            corresponding stride. Defaults to 0.5.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, strides, offset=0.5):\n",
    "        self.strides = [_pair(stride) for stride in strides]\n",
    "        self.offset = offset\n",
    "\n",
    "    @property\n",
    "    def num_levels(self):\n",
    "        \"\"\"int: number of feature levels that the generator will be applied\"\"\"\n",
    "        return len(self.strides)\n",
    "\n",
    "    @property\n",
    "    def num_base_priors(self):\n",
    "        \"\"\"list[int]: The number of priors (points) at a point\n",
    "        on the feature grid\"\"\"\n",
    "        return [1 for _ in range(len(self.strides))]\n",
    "\n",
    "    def _meshgrid(self, x, y, row_major=True):\n",
    "        yy, xx = torch.meshgrid(y, x)\n",
    "        if row_major:\n",
    "            # warning .flatten() would cause error in ONNX exporting\n",
    "            # have to use reshape here\n",
    "            return xx.reshape(-1), yy.reshape(-1)\n",
    "\n",
    "        else:\n",
    "            return yy.reshape(-1), xx.reshape(-1)\n",
    "\n",
    "    def grid_priors(self,\n",
    "                    featmap_sizes,\n",
    "                    dtype=torch.float32,\n",
    "                    device='cuda',\n",
    "                    with_stride=False):\n",
    "        \"\"\"Generate grid points of multiple feature levels.\n",
    "\n",
    "        Args:\n",
    "            featmap_sizes (list[tuple]): List of feature map sizes in\n",
    "                multiple feature levels, each size arrange as\n",
    "                as (h, w).\n",
    "            dtype (:obj:`dtype`): Dtype of priors. Default: torch.float32.\n",
    "            device (str): The device where the anchors will be put on.\n",
    "            with_stride (bool): Whether to concatenate the stride to\n",
    "                the last dimension of points.\n",
    "\n",
    "        Return:\n",
    "            list[torch.Tensor]: Points of  multiple feature levels.\n",
    "            The sizes of each tensor should be (N, 2) when with stride is\n",
    "            ``False``, where N = width * height, width and height\n",
    "            are the sizes of the corresponding feature level,\n",
    "            and the last dimension 2 represent (coord_x, coord_y),\n",
    "            otherwise the shape should be (N, 4),\n",
    "            and the last dimension 4 represent\n",
    "            (coord_x, coord_y, stride_w, stride_h).\n",
    "        \"\"\"\n",
    "\n",
    "        assert self.num_levels == len(featmap_sizes)\n",
    "        multi_level_priors = []\n",
    "        for i in range(self.num_levels):\n",
    "            priors = self.single_level_grid_priors(\n",
    "                featmap_sizes[i],\n",
    "                level_idx=i,\n",
    "                dtype=dtype,\n",
    "                device=device,\n",
    "                with_stride=with_stride)\n",
    "            multi_level_priors.append(priors)\n",
    "        return multi_level_priors\n",
    "\n",
    "    def single_level_grid_priors(self,\n",
    "                                 featmap_size,\n",
    "                                 level_idx,\n",
    "                                 dtype=torch.float32,\n",
    "                                 device='cuda',\n",
    "                                 with_stride=False):\n",
    "        \"\"\"Generate grid Points of a single level.\n",
    "\n",
    "        Note:\n",
    "            This function is usually called by method ``self.grid_priors``.\n",
    "\n",
    "        Args:\n",
    "            featmap_size (tuple[int]): Size of the feature maps, arrange as\n",
    "                (h, w).\n",
    "            level_idx (int): The index of corresponding feature map level.\n",
    "            dtype (:obj:`dtype`): Dtype of priors. Default: torch.float32.\n",
    "            device (str, optional): The device the tensor will be put on.\n",
    "                Defaults to 'cuda'.\n",
    "            with_stride (bool): Concatenate the stride to the last dimension\n",
    "                of points.\n",
    "\n",
    "        Return:\n",
    "            Tensor: Points of single feature levels.\n",
    "            The shape of tensor should be (N, 2) when with stride is\n",
    "            ``False``, where N = width * height, width and height\n",
    "            are the sizes of the corresponding feature level,\n",
    "            and the last dimension 2 represent (coord_x, coord_y),\n",
    "            otherwise the shape should be (N, 4),\n",
    "            and the last dimension 4 represent\n",
    "            (coord_x, coord_y, stride_w, stride_h).\n",
    "        \"\"\"\n",
    "        feat_h, feat_w = featmap_size\n",
    "        stride_w, stride_h = self.strides[level_idx]\n",
    "        shift_x = (torch.arange(0, feat_w, device=device) +\n",
    "                   self.offset) * stride_w\n",
    "        # keep featmap_size as Tensor instead of int, so that we\n",
    "        # can convert to ONNX correctly\n",
    "        shift_x = shift_x.to(dtype)\n",
    "\n",
    "        shift_y = (torch.arange(0, feat_h, device=device) +\n",
    "                   self.offset) * stride_h\n",
    "        # keep featmap_size as Tensor instead of int, so that we\n",
    "        # can convert to ONNX correctly\n",
    "        shift_y = shift_y.to(dtype)\n",
    "        shift_xx, shift_yy = self._meshgrid(shift_x, shift_y)\n",
    "        if not with_stride:\n",
    "            shifts = torch.stack([shift_xx, shift_yy], dim=-1)\n",
    "        else:\n",
    "            # use `shape[0]` instead of `len(shift_xx)` for ONNX export\n",
    "            stride_w = shift_xx.new_full((shift_xx.shape[0], ),\n",
    "                                         stride_w).to(dtype)\n",
    "            stride_h = shift_xx.new_full((shift_yy.shape[0], ),\n",
    "                                         stride_h).to(dtype)\n",
    "            shifts = torch.stack([shift_xx, shift_yy, stride_w, stride_h],\n",
    "                                 dim=-1)\n",
    "        all_points = shifts.to(device)\n",
    "        return all_points\n",
    "\n",
    "    def valid_flags(self, featmap_sizes, pad_shape, device='cuda'):\n",
    "        \"\"\"Generate valid flags of points of multiple feature levels.\n",
    "\n",
    "        Args:\n",
    "            featmap_sizes (list(tuple)): List of feature map sizes in\n",
    "                multiple feature levels, each size arrange as\n",
    "                as (h, w).\n",
    "            pad_shape (tuple(int)): The padded shape of the image,\n",
    "                 arrange as (h, w).\n",
    "            device (str): The device where the anchors will be put on.\n",
    "\n",
    "        Return:\n",
    "            list(torch.Tensor): Valid flags of points of multiple levels.\n",
    "        \"\"\"\n",
    "        assert self.num_levels == len(featmap_sizes)\n",
    "        multi_level_flags = []\n",
    "        for i in range(self.num_levels):\n",
    "            point_stride = self.strides[i]\n",
    "            feat_h, feat_w = featmap_sizes[i]\n",
    "            h, w = pad_shape[:2]\n",
    "            valid_feat_h = min(int(np.ceil(h / point_stride[1])), feat_h)\n",
    "            valid_feat_w = min(int(np.ceil(w / point_stride[0])), feat_w)\n",
    "            flags = self.single_level_valid_flags((feat_h, feat_w),\n",
    "                                                  (valid_feat_h, valid_feat_w),\n",
    "                                                  device=device)\n",
    "            multi_level_flags.append(flags)\n",
    "        return multi_level_flags\n",
    "\n",
    "    def single_level_valid_flags(self,\n",
    "                                 featmap_size,\n",
    "                                 valid_size,\n",
    "                                 device='cuda'):\n",
    "        \"\"\"Generate the valid flags of points of a single feature map.\n",
    "\n",
    "        Args:\n",
    "            featmap_size (tuple[int]): The size of feature maps, arrange as\n",
    "                as (h, w).\n",
    "            valid_size (tuple[int]): The valid size of the feature maps.\n",
    "                The size arrange as as (h, w).\n",
    "            device (str, optional): The device where the flags will be put on.\n",
    "                Defaults to 'cuda'.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The valid flags of each points in a single level \\\n",
    "                feature map.\n",
    "        \"\"\"\n",
    "        feat_h, feat_w = featmap_size\n",
    "        valid_h, valid_w = valid_size\n",
    "        assert valid_h <= feat_h and valid_w <= feat_w\n",
    "        valid_x = torch.zeros(feat_w, dtype=torch.bool, device=device)\n",
    "        valid_y = torch.zeros(feat_h, dtype=torch.bool, device=device)\n",
    "        valid_x[:valid_w] = 1\n",
    "        valid_y[:valid_h] = 1\n",
    "        valid_xx, valid_yy = self._meshgrid(valid_x, valid_y)\n",
    "        valid = valid_xx & valid_yy\n",
    "        return valid\n",
    "\n",
    "    def sparse_priors(self,\n",
    "                      prior_idxs,\n",
    "                      featmap_size,\n",
    "                      level_idx,\n",
    "                      dtype=torch.float32,\n",
    "                      device='cuda'):\n",
    "        \"\"\"Generate sparse points according to the ``prior_idxs``.\n",
    "\n",
    "        Args:\n",
    "            prior_idxs (Tensor): The index of corresponding anchors\n",
    "                in the feature map.\n",
    "            featmap_size (tuple[int]): feature map size arrange as (w, h).\n",
    "            level_idx (int): The level index of corresponding feature\n",
    "                map.\n",
    "            dtype (obj:`torch.dtype`): Date type of points. Defaults to\n",
    "                ``torch.float32``.\n",
    "            device (obj:`torch.device`): The device where the points is\n",
    "                located.\n",
    "        Returns:\n",
    "            Tensor: Anchor with shape (N, 2), N should be equal to\n",
    "            the length of ``prior_idxs``. And last dimension\n",
    "            2 represent (coord_x, coord_y).\n",
    "        \"\"\"\n",
    "        height, width = featmap_size\n",
    "        x = (prior_idxs % width + self.offset) * self.strides[level_idx][0]\n",
    "        y = ((prior_idxs // width) % height +\n",
    "             self.offset) * self.strides[level_idx][1]\n",
    "        prioris = torch.stack([x, y], 1).to(dtype)\n",
    "        prioris = prioris.to(device)\n",
    "        return prioris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv.ops.nms import batched_nms\n",
    "\n",
    "def _bbox_decode(priors, bbox_preds):\n",
    "        xys = (bbox_preds[..., :2] * priors[:, 2:]) + priors[:, :2]\n",
    "        whs = bbox_preds[..., 2:].exp() * priors[:, 2:]\n",
    "\n",
    "        tl_x = (xys[..., 0] - whs[..., 0] / 2)\n",
    "        tl_y = (xys[..., 1] - whs[..., 1] / 2)\n",
    "        br_x = (xys[..., 0] + whs[..., 0] / 2)\n",
    "        br_y = (xys[..., 1] + whs[..., 1] / 2)\n",
    "\n",
    "        decoded_bboxes = torch.stack([tl_x, tl_y, br_x, br_y], -1)\n",
    "        return decoded_bboxes\n",
    "\n",
    "def _bboxes_nms(cls_scores, bboxes, score_factor, cfg):\n",
    "    max_scores, labels = torch.max(cls_scores, 1)\n",
    "    valid_mask = score_factor * max_scores >= 0.5\n",
    "\n",
    "    bboxes = bboxes[valid_mask]\n",
    "    scores = max_scores[valid_mask] * score_factor[valid_mask]\n",
    "    labels = labels[valid_mask]\n",
    "\n",
    "    if labels.numel() == 0:\n",
    "        return bboxes, labels\n",
    "    else:\n",
    "        dets, keep = batched_nms(bboxes, scores, labels, 'nms')\n",
    "        return dets, labels[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes(\n",
    "                cls_scores,\n",
    "                bbox_preds,\n",
    "                objectnesses,\n",
    "                img_metas=None,\n",
    "                cfg=None,\n",
    "                rescale=False,\n",
    "                with_nms=True):\n",
    "    \"\"\"Transform network outputs of a batch into bbox results.\n",
    "    Args:\n",
    "        cls_scores (list[Tensor]): Classification scores for all\n",
    "            scale levels, each is a 4D-tensor, has shape\n",
    "            (batch_size, num_priors * num_classes, H, W).\n",
    "        bbox_preds (list[Tensor]): Box energies / deltas for all\n",
    "            scale levels, each is a 4D-tensor, has shape\n",
    "            (batch_size, num_priors * 4, H, W).\n",
    "        objectnesses (list[Tensor], Optional): Score factor for\n",
    "            all scale level, each is a 4D-tensor, has shape\n",
    "            (batch_size, 1, H, W).\n",
    "        img_metas (list[dict], Optional): Image meta info. Default None.\n",
    "        cfg (mmcv.Config, Optional): Test / postprocessing configuration,\n",
    "            if None, test_cfg would be used.  Default None.\n",
    "        rescale (bool): If True, return boxes in original image space.\n",
    "            Default False.\n",
    "        with_nms (bool): If True, do nms before return boxes.\n",
    "            Default True.\n",
    "    Returns:\n",
    "        list[list[Tensor, Tensor]]: Each item in result_list is 2-tuple.\n",
    "            The first item is an (n, 5) tensor, where the first 4 columns\n",
    "            are bounding box positions (tl_x, tl_y, br_x, br_y) and the\n",
    "            5-th column is a score between 0 and 1. The second item is a\n",
    "            (n,) tensor where each item is the predicted class label of\n",
    "            the corresponding box.\n",
    "    \"\"\"\n",
    "    prior_generator = MlvlPointGenerator(strides=[8, 16, 32], offset=0)\n",
    "    assert len(cls_scores) == len(bbox_preds) == len(objectnesses)\n",
    "    # cfg = self.test_cfg if cfg is None else cfg\n",
    "    scale_factors = [1]*4\n",
    "\n",
    "    num_imgs = len(scale_factors)\n",
    "    featmap_sizes = [cls_score.shape[2:] for cls_score in cls_scores]\n",
    "    mlvl_priors = prior_generator.grid_priors(\n",
    "        featmap_sizes,\n",
    "        dtype=cls_scores[0].dtype,\n",
    "        device=cls_scores[0].device,\n",
    "        with_stride=True)\n",
    "\n",
    "    # flatten cls_scores, bbox_preds and objectness\n",
    "    flatten_cls_scores = [\n",
    "        cls_score.permute(0, 2, 3, 1).reshape(num_imgs, -1,\n",
    "                                                2)\n",
    "        for cls_score in cls_scores\n",
    "    ]\n",
    "    flatten_bbox_preds = [\n",
    "        bbox_pred.permute(0, 2, 3, 1).reshape(num_imgs, -1, 4)\n",
    "        for bbox_pred in bbox_preds\n",
    "    ]\n",
    "    flatten_objectness = [\n",
    "        objectness.permute(0, 2, 3, 1).reshape(num_imgs, -1)\n",
    "        for objectness in objectnesses\n",
    "    ]\n",
    "\n",
    "    flatten_cls_scores = torch.cat(flatten_cls_scores, dim=1).sigmoid()\n",
    "    flatten_bbox_preds = torch.cat(flatten_bbox_preds, dim=1)\n",
    "    flatten_objectness = torch.cat(flatten_objectness, dim=1).sigmoid()\n",
    "    flatten_priors = torch.cat(mlvl_priors)\n",
    "\n",
    "    flatten_bboxes = _bbox_decode(flatten_priors, flatten_bbox_preds)\n",
    "\n",
    "    if rescale:\n",
    "        flatten_bboxes[..., :4] /= flatten_bboxes.new_tensor(\n",
    "            scale_factors).unsqueeze(1)\n",
    "\n",
    "    result_list = []\n",
    "    for img_id in range(4):\n",
    "        cls_scores = flatten_cls_scores[img_id]\n",
    "        score_factor = flatten_objectness[img_id]\n",
    "        bboxes = flatten_bboxes[img_id]\n",
    "\n",
    "        result_list.append(\n",
    "            _bboxes_nms(cls_scores, bboxes, score_factor, None))\n",
    "\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10925/3890320334.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_10925/3596645286.py\u001b[0m in \u001b[0;36mget_bboxes\u001b[0;34m(cls_scores, bbox_preds, objectnesses, img_metas, cfg, rescale, with_nms)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mresult_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mcls_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_cls_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mscore_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_objectness\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "get_bboxes(answer[0], answer[1], answer[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/models/backbones/resnet.py:597: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.size(1) == self.encoder_channels[i]:\n"
     ]
    }
   ],
   "source": [
    "traced = torch.jit.trace(model.forward, torch.rand(4, 3, 224, 224, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced.save('/mnt/ext1/fips-benchmark/models/siloiz_contrastive_xbm_resnet50_adam_512d.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
