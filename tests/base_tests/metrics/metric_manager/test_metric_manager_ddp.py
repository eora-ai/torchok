import unittest
from torchok import METRICS
from torchok.metrics.metrics_manager import MetricParams, MetricsManager, Phase

from pytorch_lightning import LightningModule, Trainer
import torch
from torch.nn import functional as F
from torch.utils.data import DataLoader, Dataset
from torchmetrics import Metric

from typing import List

INPUT_DATA_SHAPE = 16
BATCH_SIZE = 4
EPOCH = 5

labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,
          9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

predicts = [0, 0, 1, 3, 3, 4, 5, 6, 7, 0, 0, 1, 1, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 5, 5, 6, 6, 7, 7,
            8, 8, 9, 9, 7, 7, 8, 8, 8, 8, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 9]

uniq_label_count = 10
accuracy_answer = 0.18


class FakeData(Dataset):
    def __init__(self, labels=labels, predicts=predicts):
        self.labels = labels
        self.predicts = predicts

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, item):
        return torch.rand(INPUT_DATA_SHAPE), torch.tensor(self.predicts[item]), torch.tensor(self.labels[item])


@METRICS.register_class
class MetricMemoryBlock(Metric):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.add_state("memory_list", default=[], dist_reduce_fx=None)

    def update(self, state: torch.Tensor):
        self.memory_list.append(state)

    def compute(self):
        return torch.tensor((torch.cat(self.memory_list)).shape[0])


class Model(LightningModule):
    def __init__(self, metric_params: List[MetricParams]):
        super().__init__()
        self.l1 = torch.nn.Linear(INPUT_DATA_SHAPE, uniq_label_count)
        self.metric_manager = MetricsManager(metric_params)

    def forward(self, x):
        return torch.relu(self.l1(x.view(x.size(0), -1)))

    def training_step(self, batch, batch_nb):
        input, fake_predict, fake_target = batch
        predict = self(input)
        loss = F.cross_entropy(predict, fake_target)
        # set fake data to output, to check metrics
        output = dict(predict=fake_predict, target=fake_target)
        self.metric_manager.update(Phase.TRAIN, **output)
        return loss

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=0.02)


def run_model(metric_params: List[MetricParams]):
    train_ds = FakeData()
    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE)

    mnist_model = Model(metric_params)

    # Initialize a trainer
    trainer = Trainer(
        accelerator="cpu",
        strategy="ddp",
        num_processes=2,
        max_epochs=EPOCH,
    )

    # Train the model âš¡
    trainer.fit(mnist_model, train_loader)

    metric_manager_answer = mnist_model.metric_manager.on_epoch_end(Phase.TRAIN)
    return metric_manager_answer


class TestCase:
    def __init__(self, test_name: str, metric_params: List[MetricParams], expected):
        self.test_name = test_name
        self.metric_params = metric_params
        self.expected = expected


class DDPMetricManagerTest(unittest.TestCase):
    accuracy_mapping = dict(preds='predict', target='target')
    accuracy_params = MetricParams(
        name='Accuracy', mapping=accuracy_mapping,
        phases=[Phase.TRAIN])

    accuracy_answer = {'train/Accuracy': accuracy_answer}

    memory_bank_mapping = dict(state='predict')
    memory_block_params = MetricParams(
        name='MetricMemoryBlock', mapping=memory_bank_mapping,
        phases=[Phase.TRAIN]
    )
    memory_block_answer = {'train/MetricMemoryBlock': len(labels) * EPOCH}

    def test(self):
        testcases = [
            TestCase(
                test_name='Accuracy',
                metric_params=[self.accuracy_params],
                expected=self.accuracy_answer
            ),
            TestCase(
                test_name='MetricMemoryBlock',
                metric_params=[self.memory_block_params],
                expected=self.memory_block_answer
            ),
        ]
        for case in testcases:
            actual = run_model(
                metric_params=case.metric_params
            )
            self.assertDictEqual(
                case.expected,
                actual,
                "failed test {} expected {}, actual {}".format(
                    case.test_name, case.expected, actual
                ),
            )


if __name__ == '__main__':
    unittest.main()
