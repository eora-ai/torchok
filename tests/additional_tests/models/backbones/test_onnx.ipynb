{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "import sys\n",
    "sys.path.append('../../../../')\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import onnx\n",
    "\n",
    "from torchok.constructor import BACKBONES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TestHRNet(unittest.TestCase):\n",
    "    def __init__(self, testName, backbone_name):\n",
    "        super().__init__(testName)\n",
    "        self.backbone_name = backbone_name\n",
    "\n",
    "    def test_onnx(self):\n",
    "        self._onnx_model = Path(f'{self.backbone_name}.onnx')\n",
    "        self._input = torch.ones(1, 3, 224, 224)\n",
    "        #self._input = torch.ones(1, 3, 384, 384)\n",
    "        #self._input = torch.ones(1, 3, 256, 256)\n",
    "        self.backbone = BACKBONES.get(self.backbone_name)(pretrained=False, in_chans=3)\n",
    "        torch.onnx.export(self.backbone,\n",
    "                          self._input,\n",
    "                          self._onnx_model,\n",
    "                          opset_version=12)\n",
    "        model = onnx.load(self._onnx_model)\n",
    "        onnx.checker.check_model(model)\n",
    "        self._onnx_model.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beit_base_patch16_224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1656352463056/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 8.372s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beit_base_patch16_384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/beit.py\", line 182, in forward\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (384).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.534s\n",
      "\n",
      "FAILED (failures=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beit_base_patch16_224_in22k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 7.761s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beit_large_patch16_224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 29.118s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beit_large_patch16_384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/beit.py\", line 182, in forward\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (384).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.713s\n",
      "\n",
      "FAILED (failures=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beit_large_patch16_512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/beit.py\", line 182, in forward\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (512).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.636s\n",
      "\n",
      "FAILED (failures=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beit_large_patch16_224_in22k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 26.591s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davit_t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/davit.py:353: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
      "/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/davit.py:197: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
      "/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/davit.py:369: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n",
      "/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/davit.py:154: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.831s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davit_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/davit.py:353: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
      "/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/davit.py:197: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
      "/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/davit.py:369: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n",
      "/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/davit.py:154: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 22.565s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davit_b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/davit.py:353: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
      "/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/davit.py:197: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
      "/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/davit.py:369: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n",
      "/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/davit.py:154: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 24.362s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnasnet_050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.581s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnasnet_075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.641s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnasnet_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.721s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnasnet_b1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.741s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnasnet_140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.861s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semnasnet_050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.318s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semnasnet_075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.386s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semnasnet_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.431s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnasnet_a1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.432s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semnasnet_140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.578s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnasnet_small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.371s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv2_035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.884s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv2_050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.931s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv2_075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.953s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv2_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.008s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv2_140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.123s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv2_110d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.652s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv2_120d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.327s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbnetc_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.983s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spnasnet_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.869s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.686s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 9.028s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 9.088s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b2a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 9.098s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 11.692s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b3a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 11.732s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 18.184s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 27.525s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 37.864s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 58.341s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 74.383s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_l2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 189.150s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... /opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/functional.py:2515: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  _verify_batch_size([input.size(0) * input.size(1) // num_groups, num_groups] + list(input.size()[2:]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b0_gn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.749s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... /opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/functional.py:2515: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  _verify_batch_size([input.size(0) * input.size(1) // num_groups, num_groups] + list(input.size()[2:]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b0_g8_gn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.784s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b0_g16_evos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 5.082s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b3_gn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/functional.py:2515: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  _verify_batch_size([input.size(0) * input.size(1) // num_groups, num_groups] + list(input.size()[2:]))\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 11.240s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b3_g8_gn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/functional.py:2515: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  _verify_batch_size([input.size(0) * input.size(1) // num_groups, num_groups] + list(input.size()[2:]))\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 11.395s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_es\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.812s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_em\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.246s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_el\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 5.402s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_cc_b0_4e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 11.063s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_cc_b0_8e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 11.260s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_cc_b1_8e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 22.220s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_lite0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.993s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_lite1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.786s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_lite2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.668s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_lite3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 5.943s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_lite4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 9.367s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnetv2_rw_t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 21.000s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gc_efficientnetv2_rw_t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 44.660s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnetv2_rw_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 23.167s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnetv2_rw_m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 57.494s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnetv2_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 22.511s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnetv2_m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 49.326s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnetv2_l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 100.512s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnetv2_xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 176.764s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... /opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.812s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 12.287s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 12.339s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 15.429s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 22.973s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 33.311s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 44.520s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 66.268s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 83.106s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... /opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b0_ap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.747s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b1_ap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 12.267s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b2_ap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 12.236s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b3_ap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 15.367s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b4_ap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 22.719s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b5_ap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 33.406s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b6_ap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 44.946s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b7_ap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 67.059s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b8_ap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 82.699s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... /opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b0_ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.713s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b1_ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 12.088s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b2_ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 12.184s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b3_ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 15.339s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b4_ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 23.156s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b5_ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 33.281s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b6_ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 44.759s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_b7_ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 67.087s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_l2_ns_475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 200.746s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_l2_ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 200.412s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... /opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_es\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.072s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_em\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 5.927s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_el\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 7.392s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_cc_b0_4e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 731, in _model_to_graph\n",
      "    graph = _optimize_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 308, in _optimize_graph\n",
      "    graph = _C._jit_pass_onnx(graph, operator_export_type)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 416, in _run_symbolic_function\n",
      "    return utils._run_symbolic_function(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1406, in _run_symbolic_function\n",
      "    return symbolic_fn(g, *inputs, **attrs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py\", line 232, in wrapper\n",
      "    return fn(g, *args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py\", line 1684, in _convolution\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Unsupported: ONNX export of convolution for kernel of unknown shape.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.551s\n",
      "\n",
      "FAILED (errors=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_cc_b0_8e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 731, in _model_to_graph\n",
      "    graph = _optimize_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 308, in _optimize_graph\n",
      "    graph = _C._jit_pass_onnx(graph, operator_export_type)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 416, in _run_symbolic_function\n",
      "    return utils._run_symbolic_function(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1406, in _run_symbolic_function\n",
      "    return symbolic_fn(g, *inputs, **attrs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py\", line 232, in wrapper\n",
      "    return fn(g, *args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py\", line 1684, in _convolution\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Unsupported: ONNX export of convolution for kernel of unknown shape.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.790s\n",
      "\n",
      "FAILED (errors=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_cc_b1_8e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 731, in _model_to_graph\n",
      "    graph = _optimize_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 308, in _optimize_graph\n",
      "    graph = _C._jit_pass_onnx(graph, operator_export_type)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 416, in _run_symbolic_function\n",
      "    return utils._run_symbolic_function(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1406, in _run_symbolic_function\n",
      "    return symbolic_fn(g, *inputs, **attrs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py\", line 232, in wrapper\n",
      "    return fn(g, *args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py\", line 1684, in _convolution\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Unsupported: ONNX export of convolution for kernel of unknown shape.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.298s\n",
      "\n",
      "FAILED (errors=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_lite0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.567s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... /opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_lite1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.387s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_lite2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.391s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... /opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_lite3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 8.027s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnet_lite4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 11.791s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 26.656s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 56.217s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 108.834s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_s_in21ft1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 26.405s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_m_in21ft1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 55.058s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_l_in21ft1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 108.638s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_xl_in21ft1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 187.681s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_s_in21k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 26.532s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_m_in21k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 55.748s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_l_in21k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 110.393s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_xl_in21k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 190.056s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... /opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 8.415s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_b1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 12.056s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_b2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 13.401s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_efficientnetv2_b3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 17.376s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixnet_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 9.584s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixnet_m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 14.668s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixnet_l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 14.989s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixnet_xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 22.790s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixnet_xxl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 24.626s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... /opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_mixnet_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 16.233s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... /opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_mixnet_m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 24.477s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_mixnet_l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 24.541s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinynet_a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.809s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinynet_b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 5.014s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinynet_c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.365s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinynet_d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.666s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinynet_e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.345s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrnet_w18_small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 5.341s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrnet_w18_small_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 21.627s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrnet_w18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 108.190s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrnet_w30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 108.525s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrnet_w32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 108.667s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrnet_w40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 109.082s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrnet_w44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 109.683s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrnet_w48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 109.821s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrnet_w64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 111.887s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv3_large_075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.490s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv3_large_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.524s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv3_large_100_miil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.589s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv3_large_100_miil_in21k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.468s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv3_small_050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.414s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv3_small_075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.445s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv3_small_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.458s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenetv3_rw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.520s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... /opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_mobilenetv3_large_075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.815s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_mobilenetv3_large_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.930s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... /opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_mobilenetv3_large_minimal_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.636s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_mobilenetv3_small_075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.668s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_mobilenetv3_small_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.681s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_mobilenetv3_small_minimal_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/padding.py:32: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.448s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbnetv3_b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 12.135s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbnetv3_d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 14.331s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbnetv3_g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 18.490s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcnet_035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.261s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcnet_050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.314s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcnet_075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.378s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcnet_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.322s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcnet_150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.416s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet10t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.714s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet14t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.074s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.102s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.247s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.344s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet34d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.516s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.720s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet26t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.914s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet26d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.910s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.847s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.096s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.101s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 11.625s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet101d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 12.276s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 25.328s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet152d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 26.285s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 43.583s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet200d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 45.415s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tv_resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.335s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tv_resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.873s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tv_resnet101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 11.814s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tv_resnet152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 25.494s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wide_resnet50_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 5.172s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wide_resnet101_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 14.160s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50_gn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/functional.py:2515: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  _verify_batch_size([input.size(0) * input.size(1) // num_groups, num_groups] + list(input.size()[2:]))\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.685s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnext50_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.827s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnext50d_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.155s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnext101_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 11.799s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnext101_32x8d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 13.131s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnext101_64x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 13.048s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tv_resnext50_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.829s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ig_resnext101_32x8d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 13.269s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ig_resnext101_32x16d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 16.058s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ig_resnext101_32x32d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 28.356s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ig_resnext101_32x48d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1110, in _export\n",
      "    ) = graph._export_onnx(  # type: ignore[attr-defined]\n",
      "RuntimeError: The serialized model is larger than the 2GiB limit imposed by the protobuf library. Therefore the output file must be a file path, so that the ONNX external data can be written to the same directory. Please specify the output file name.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 30.673s\n",
      "\n",
      "FAILED (errors=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssl_resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.135s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssl_resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.930s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssl_resnext50_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.851s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssl_resnext101_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 11.732s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssl_resnext101_32x8d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 13.013s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssl_resnext101_32x16d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 16.111s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swsl_resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.150s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swsl_resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.856s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swsl_resnext50_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.833s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swsl_resnext101_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 11.753s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swsl_resnext101_32x8d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 13.083s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swsl_resnext101_32x16d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 16.058s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecaresnet26t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.803s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecaresnet50d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.871s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecaresnet50t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.877s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecaresnetlight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.885s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecaresnet101d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 24.405s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecaresnet200d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 99.295s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecaresnet269d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 187.683s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecaresnext26t_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.731s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecaresnext50t_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.773s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.709s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.186s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.348s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnet50t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.737s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnet101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 22.788s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnet152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 53.555s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnet152d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 54.681s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnet200d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 96.590s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnet269d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 182.336s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnext26d_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.715s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnext26t_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.720s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnext26tn_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.732s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnext50_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.458s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnext101_32x4d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 23.061s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnext101_32x8d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 24.358s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnext101d_32x8d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 25.239s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senet154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 55.403s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnetblur18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.350s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnetblur50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.268s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnetblur50d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.526s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnetblur101d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "Warning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 13.134s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnetaa50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 3.985s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnetaa50d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 4.252s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnetaa101d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 12.434s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnetaa50d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.831s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seresnextaa101d_32x8d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 25.520s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnetrs50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 7.055s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnetrs101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 24.439s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnetrs152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 55.633s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnetrs200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 96.942s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnetrs270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 186.255s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnetrs350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 321.790s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnetrs420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 475.621s\n",
      "\n",
      "OK\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swinv2_tiny_window16_256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 249, in forward\n",
      "    x = self._forward_patch_emb(x)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 210, in _forward_patch_emb\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (256).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.485s\n",
      "\n",
      "FAILED (failures=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swinv2_tiny_window8_256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 249, in forward\n",
      "    x = self._forward_patch_emb(x)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 210, in _forward_patch_emb\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (256).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.464s\n",
      "\n",
      "FAILED (failures=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swinv2_small_window16_256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 249, in forward\n",
      "    x = self._forward_patch_emb(x)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 210, in _forward_patch_emb\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (256).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.831s\n",
      "\n",
      "FAILED (failures=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swinv2_small_window8_256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 249, in forward\n",
      "    x = self._forward_patch_emb(x)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 210, in _forward_patch_emb\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (256).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.868s\n",
      "\n",
      "FAILED (failures=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swinv2_base_window16_256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 249, in forward\n",
      "    x = self._forward_patch_emb(x)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 210, in _forward_patch_emb\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (256).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.342s\n",
      "\n",
      "FAILED (failures=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swinv2_base_window8_256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 249, in forward\n",
      "    x = self._forward_patch_emb(x)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 210, in _forward_patch_emb\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (256).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.333s\n",
      "\n",
      "FAILED (failures=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swinv2_base_window12_192_22k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 249, in forward\n",
      "    x = self._forward_patch_emb(x)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 210, in _forward_patch_emb\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (192).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.368s\n",
      "\n",
      "FAILED (failures=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swinv2_base_window12to16_192to256_22kft1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 249, in forward\n",
      "    x = self._forward_patch_emb(x)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 210, in _forward_patch_emb\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (256).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.436s\n",
      "\n",
      "FAILED (failures=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swinv2_base_window12to24_192to384_22kft1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 249, in forward\n",
      "    x = self._forward_patch_emb(x)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 210, in _forward_patch_emb\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (384).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.427s\n",
      "\n",
      "FAILED (failures=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swinv2_large_window12_192_22k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 249, in forward\n",
      "    x = self._forward_patch_emb(x)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 210, in _forward_patch_emb\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (192).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.858s\n",
      "\n",
      "FAILED (failures=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swinv2_large_window12to16_192to256_22kft1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 249, in forward\n",
      "    x = self._forward_patch_emb(x)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 210, in _forward_patch_emb\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (256).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.808s\n",
      "\n",
      "FAILED (failures=1)\n",
      "test_onnx (__main__.TestHRNet) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swinv2_large_window12to24_192to384_22kft1k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py:833: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_onnx (__main__.TestHRNet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_5861/466737919.py\", line 10, in test_onnx\n",
      "    torch.onnx.export(self.backbone,\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/__init__.py\", line 350, in export\n",
      "    return utils.export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 163, in export\n",
      "    _export(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 1074, in _export\n",
      "    graph, params_dict, torch_out = _model_to_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 727, in _model_to_graph\n",
      "    graph, params, torch_out, module = _create_jit_graph(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 602, in _create_jit_graph\n",
      "    graph, torch_out = _trace_and_get_graph_from_model(model, args)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/onnx/utils.py\", line 517, in _trace_and_get_graph_from_model\n",
      "    trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 1175, in _get_trace_graph\n",
      "    outs = ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 127, in forward\n",
      "    graph, out = torch._C._create_graph_by_tracing(\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/jit/_trace.py\", line 118, in wrapper\n",
      "    outs.append(self.inner(*trace_inputs))\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 249, in forward\n",
      "    x = self._forward_patch_emb(x)\n",
      "  File \"/workdir/vpatrushev/torchOKsmall2/torchok/tests/additional_tests/models/backbones/../../../../torchok/models/backbones/swin.py\", line 210, in _forward_patch_emb\n",
      "    x = self.patch_embed(x)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1118, in _slow_forward\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/timm/models/layers/patch_embed.py\", line 33, in forward\n",
      "    _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n",
      "  File \"/opt/conda/envs/torchok/lib/python3.8/site-packages/torch/__init__.py\", line 833, in _assert\n",
      "    assert condition, message\n",
      "AssertionError: Input image height (224) doesn't match model (384).\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.910s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "for backbone_name in BACKBONES.entrypoints.keys():\n",
    "    print(backbone_name)\n",
    "    suite = unittest.TestSuite()\n",
    "    suite.addTest(TestHRNet('test_onnx', backbone_name))\n",
    "    unittest.TextTestRunner(verbosity=2).run(suite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('torchok')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d98e06cf72c4d3f13daa3b7355ff9823c938a29cb0c8751ac8d58eb5a0740c19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
